import { Callout } from "nextra/components"
import { Steps } from "nextra/components"
import { Tabs } from "nextra/components"
import { Cards } from 'nextra/components'

# Get Started with AI Agent Tracing

> **See inside your AI agents in under 5 minutes.** Add comprehensive tracing to understand what your agents are doing, why they're failing, and how to make them better.

This guide walks you through adding Handit.ai tracing to your AI agents. You'll capture every LLM call, tool execution, and operation with complete inputs, outputs, timing, and error details.

<Callout type="info">
  **What you'll build:** Complete observability for your AI agent with automatic tracking of all LLM nodes and tools, capturing the full execution flow from user request to final response.
</Callout>

## Quick Overview

Here's what we'll accomplish:

<Steps>
### Create Your Agent
Set up your agent structure in the Handit.ai Dashboard and get your configuration file

### Get Your Integration Token
Obtain your API key from Settings > Integrations to connect your code to Handit.ai

### Install & Configure
Set up the SDK and connect to Handit.ai with your integration token

### Add Tracing
Wrap your agent functions to automatically capture execution details

### See Results
View complete traces, debug issues, and optimize performance
</Steps>

## Create Your Agent in Handit Dashboard

**Start here first!** Before writing any code, you need to define your agent's structure in the Handit.ai Dashboard. This creates the blueprint that your tracing code will follow.

### Step 1: Navigate to Your Agents

1. Log into your [Handit.ai Dashboard](https://app.handit.ai)
2. Go to **"My Agents"** in the navigation menu
3. Click **"Create New Agent"**

<video 
  width="100%" 
  autoPlay 
  loop 
  muted 
  playsInline
  style={{ borderRadius: '8px', border: '1px solid #e5e7eb' }}
>
  <source src="/assets/quickstart/create_agent.mp4" type="video/mp4" />
  Your browser does not support the video tag.
</video>

### Step 2: Choose Your Creation Method

You have two powerful options to create your agent:

<Tabs items={['ðŸ¤– AI-Powered Creation', 'ðŸŽ¨ Visual Builder']}>
<Tabs.Tab>
**Upload JSON & Let AI Do the Work**

Perfect if you already have your agent structure documented or want to quickly import an existing setup.

**How it works:**
1. **Prepare your JSON file** with your agent's structure (see example below)
2. **Upload the file** in the dashboard
3. **Handit's AI analyzes** your structure and normalizes it
4. **Review and confirm** the generated agent configuration
5. **Download your config** with proper slugs and IDs

**Example JSON structure to upload:**
```json filename="my-agent-structure.json"
{
  "name": "Customer Support Agent",
  "description": "Handles customer inquiries with RAG and LLM",
  "workflow": [
    {
      "name": "Intent Classification",
      "type": "llm",
      "model": "gpt-4",
      "purpose": "Classify user intent from support request"
    },
    {
      "name": "Knowledge Search", 
      "type": "tool",
      "function": "vector_search",
      "purpose": "Search knowledge base for relevant information"
    },
    {
      "name": "Response Generation",
      "type": "llm", 
      "model": "gpt-4",
      "purpose": "Generate helpful response using context"
    }
  ]
}
```

<Callout type="tip">
  **Pro tip:** Your JSON doesn't need to be perfect! Handit's AI will understand various formats and structures, then normalize everything into the proper configuration format.
</Callout>
</Tabs.Tab>
<Tabs.Tab>
**Drag & Drop Visual Builder**

Perfect for building your agent structure visually and understanding the relationships between components.

**How it works:**
1. **Start with a blank canvas** in the visual builder
2. **Drag LLM nodes** from the component library
3. **Add tool nodes** for your custom functions and APIs
4. **Connect the nodes** to show your workflow
5. **Configure each node** with required information:
   - **LLM Nodes:** Model type, purpose, parameters
   - **Tool Nodes:** Function name, description, input/output types
6. **Download your config** when complete

**What you'll configure for each node:**

| **Node Type** | **Required Info** | **Example** |
|---------------|------------------|-------------|
| **LLM Node** | Model, purpose, temperature | GPT-4 for intent classification |
| **Tool Node** | Function name, description, I/O | `search_knowledge_base()` for RAG |
| **API Node** | Endpoint, method, purpose | External service integration |

**Visual Builder Benefits:**
- See your agent's flow visually
- Understand node relationships
- Validate your architecture before coding
- Easy to modify and iterate

<Callout type="info">
  **Visual learner?** The drag-and-drop builder helps you understand how your agent's components work together before you start coding.
</Callout>
</Tabs.Tab>
</Tabs>

### Step 3: Download Your Configuration

Once your agent is created (either method), you'll get a `handit.config.json` file that looks like this:

```json filename="handit.config.json"
{
  "agent": {
    "name": "Customer Support Agent",           // Your agent's display name
    "slug": "customer-support-agent",          // Unique identifier for your agent
    "description": "Handles customer inquiries with RAG and LLM"
  },
  "nodes": [
    {
      "name": "Intent Classification",          // Display name for the node
      "slug": "intent-classifier",             // ðŸ”‘ This slug is what you'll use in code
      "type": "model",                        // Node type (model, tool, etc.)
      "problem_type": "classification",       // Type of problem it solves
      "description": "Classifies user intent from support request",
      "next_nodes": ["knowledge-search"]      // Connected nodes in workflow
    },
    {
      "name": "Knowledge Search",
      "slug": "knowledge-search",              // ðŸ”‘ This slug is what you'll use in code
      "type": "tool",
      "problem_type": "retrieval",
      "description": "Searches knowledge base for relevant information",
      "next_nodes": ["response-generator"]
    },
    {
      "name": "Response Generator",
      "slug": "response-generator",            // ðŸ”‘ This slug is what you'll use in code
      "type": "model",
      "problem_type": "generation",
      "description": "Generates helpful response using context",
      "next_nodes": []
    }
  ]
}
```

<Callout type="warning">
  **Important:** Save this config file in your project! The `slug` values are what you'll use to identify nodes in your tracing code. Keep this file version-controlled with your code.
</Callout>

**Using slugs in your code:**
The `slug` values become the identifiers in your tracing implementation:

```python
# Using the intent-classifier slug from config
@tracker.trace_agent_node("intent-classifier")
async def classify_intent(user_message: str):
    # Your intent classification logic here
    return intent

# Using the knowledge-search slug from config  
@tracker.trace_agent_node("knowledge-search")
async def search_knowledge_base(intent: str, query: str):
    # Your knowledge search logic here
    return relevant_docs

# Using the response-generator slug from config
@tracker.trace_agent_node("response-generator") 
async def generate_response(context: str, user_query: str):
    # Your response generation logic here
    return response
```

<Callout type="success">
  **Ready to code?** Now that you have your agent structure defined and your config file downloaded, let's set up the SDK and add tracing to your code.
</Callout>

## Get Your Integration Token

Before installing the SDK, you need to get your integration token to connect your code to Handit.ai.

### Step 1: Navigate to Settings

1. In your [Handit.ai Dashboard](https://app.handit.ai), click on **"Settings"** in the navigation menu
2. Go to the **"Integrations"** section

### Step 2: Generate Your Token

1. **Find the SDK Integration** section
2. **Copy your integration token** - this is your API key for the SDK
3. **Keep it secure** - treat this like a password

<video 
  width="100%" 
  autoPlay 
  loop 
  muted 
  playsInline
  style={{ borderRadius: '8px', border: '1px solid #e5e7eb' }}
>
  <source src="/assets/quickstart/integration_token.mp4" type="video/mp4" />
  Your browser does not support the video tag.
</video>

<Callout type="warning">
  **Security Note:** Your integration token gives access to your Handit.ai account. Never commit it to version control or share it publicly. Always use environment variables in production.
</Callout>

**What you'll use this token for:**
- Authenticating your SDK with Handit.ai
- Sending trace data from your application
- Connecting your agent runs to your dashboard

<Callout type="tip">
  **Pro tip:** Copy this token now and save it as an environment variable. You'll need it in the next step when configuring the SDK.
</Callout>

## Install the SDK

<Tabs items={['Python', 'JavaScript']}>
<Tabs.Tab>
```bash filename="terminal"
pip install -U "handit-sdk>=1.9.0"
```
</Tabs.Tab>
<Tabs.Tab>
```bash filename="terminal"
npm install @handit.ai/node
```
</Tabs.Tab>
</Tabs>

## Configure Your Integration Token

Now let's configure the SDK with the integration token you obtained from the dashboard.

<Tabs items={['Python', 'JavaScript']}>
<Tabs.Tab>
**Best Practice:** Create a dedicated service file to centralize your tracker configuration.

First, create a `handit_service.py` file to initialize the tracker:

```python filename="handit_service.py"
# handit_service.py
from handit import HanditTracker

tracker = HanditTracker()
tracker.config(api_key="your-integration-token-here")
```

Then import the tracker in your agent code:

```python filename="agent_code.py"
from handit_service import tracker
```

<Callout type="tip">
  **Pro tip:** Use environment variables for your integration token: `tracker.config(api_key=os.getenv("HANDIT_INTEGRATION_TOKEN"))`
</Callout>
</Tabs.Tab>
<Tabs.Tab>
**Best Practice:** Initialize Handit.ai once in your application's entry point.

Initialize Handit.ai in your entry file (e.g., `index.js` or `server.js`):

```javascript filename="index.js"
import { config } from '@handit.ai/node';

config({ apiKey: "your-integration-token-here" });
```

Import the required functions in your agent code:

```javascript filename="agent.js"
import { startAgentTracing, traceAgentNode } from '@handit.ai/node';
```

<Callout type="tip">
  **Pro tip:** Use environment variables for your integration token: `config({ apiKey: process.env.HANDIT_INTEGRATION_TOKEN })`
</Callout>
</Tabs.Tab>
</Tabs>

## Add Tracing to Your Agent

Now for the fun part! Let's add tracing to capture everything your agent does.

### Step 1: Trace Your Main Agent Function

Start by wrapping your main agent functionâ€”this is the entry point that handles user requests and orchestrates the entire workflow.

<Tabs items={['Python', 'JavaScript']}>
<Tabs.Tab>
Use the `@tracker.start_agent_tracing()` decorator on your main agent function:

```python {3} filename="agent_function.py"
from handit_service import tracker

@tracker.start_agent_tracing()
async def process_message(self, user_message: str, conversation_history: list):
    # Process the user message and generate a response
    try:
        # Analyze the message intent
        intent = await self.analyze_intent(user_message)
        
        # Generate response based on intent
        response = await self.generate_response(intent, conversation_history)
        
        return {
            "response": response,
            "intent": intent,
            "status": "success"
        }
    except Exception as e:
        return {
            "error": str(e),
            "status": "error"
        }
```

<Callout type="info">
  This decorator automatically captures the complete execution flow, timing, inputs, outputs, and any errors that occur during your agent's execution.
</Callout>
</Tabs.Tab>
<Tabs.Tab>
Wrap your main agent function with `startAgentTracing`:

```javascript filename="agent_function.js"
const { startAgentTracing } = require('@handit.ai/node');

const processMessage = startAgentTracing(async (userMessage, conversationHistory) => {
    try {
        // Analyze the message intent
        const intent = await analyzeIntent(userMessage);
        
        // Generate response based on intent
        const response = await generateResponse(intent, conversationHistory);
        
        return {
            response,
            intent,
            status: "success"
        };
    } catch (error) {
        return {
            error: error.message,
            status: "error"
        };
    }
});
```

<Callout type="info">
  This wrapper automatically captures the complete execution flow, timing, inputs, outputs, and any errors that occur during your agent's execution.
</Callout>
</Tabs.Tab>
</Tabs>

### Step 2: Trace Individual Components

Next, add tracing to your individual LLM calls, tools, and functions. Choose the method that best fits your use case:

<Tabs items={['Python', 'JavaScript']}>
<Tabs.Tab>
**Choose the right method for your use case:**

```python filename="node_tracing.py"
# Method 1: Manual tracking with _send_tracked_data
# This is the most direct way to track individual component executions
await tracker._send_tracked_data(
    model_id="your-node-slug",     # Must match slug from handit.config.json
    request_body={"input": "data"}, # Input data for the operation
    response_body={"output": "data"} # Output data from the operation
)

# Method 2: Using trace_agent_node_func for async functions
# This is useful for one-off async function calls that need tracing
result = await tracker.trace_agent_node_func(
    search_documents,           # func: The async function to trace
    query="customer support",   # *args: Positional arguments for the function
    limit=5,                    # **kwargs: Keyword arguments for the function
    key="document-search"       # key: Unique identifier for this node in analytics
)

# Method 3: Using trace_agent_node decorator for async functions
# This is useful for reusable async functions that need tracing
@tracker.trace_agent_node("vector-search")  # agent_node_id: Unique identifier for this node
async def search_similar_documents(query: str, top_k: int = 5):
    # Your vector search logic here
    return results

# Method 4: Using trace_agent_node decorator for sync functions
# This is useful for reusable sync functions that need tracing
@tracker.trace_agent_node("text-processor")  # agent_node_id: Unique identifier for this node
def process_text(text: str, language: str = "en"):
    # Your text processing logic here
    return processed_text

# Method 5: Tracking an LLM model
# This wraps a language model to track all its interactions
from langchain.chat_models import ChatOpenAI

llm = ChatOpenAI(
    model_name="gpt-4",        # model: The LLM model to track
    temperature=0.7
)
tracked_llm = tracker.track_model(
    llm,                       # model: The model instance to track
    "gpt4-chat"               # model_id: Unique identifier for this model
)

# Method 6: Tracking a tool
# This wraps a tool to track all its executions
from langchain.tools import Tool

def search_database(query: str):
    # Database search logic
    return results

search_tool = Tool(
    name="database-search",    # tool: The tool to track
    func=search_database
)
tracked_tool = tracker.track_tool(
    search_tool,              # tool: The tool instance to track
    "db-search"              # tool_id: Unique identifier for this tool
)
```

**When to use each method:**
- **`_send_tracked_data`** - Direct manual tracking of individual component executions (LLMs/Tools)
- **`trace_agent_node_func`** - One-off async function calls you need to trace
- **`trace_agent_node` decorator** - Reusable functions you want to trace every time
- **`track_model`** - LLM models where you want to capture all interactions
- **`track_tool`** - Tools, RAG systems, and API calls you want to monitor

<Callout type="tip">
  **Key principle:** The `key` parameter should match the `slug` from your `handit.config.json` file for proper dashboard visualization.
</Callout>
</Tabs.Tab>
<Tabs.Tab>
**Choose the right method for your use case:**

```javascript filename="node_tracing.js"
const { traceAgentNode, captureAgentNode } = require('@handit.ai/node');

// Method 1: Manual tracking with captureAgentNode
// This is the most direct way to track individual component executions
await captureAgentNode({
    agentNodeSlug: "your-node-slug",    // Must match slug from handit.config.json
    requestBody: { input: "data" },     // Input data for the operation
    responseBody: { output: "data" }    // Output data from the operation
});

// Method 2: Using traceAgentNode for async functions
// This is useful for reusable async functions that need tracing
const searchDocuments = traceAgentNode({
    agentNodeId: "vector-search",    // Unique identifier from config
    callback: async (query, limit = 5) => {
        // Your vector search logic here
        return results;
    }
});

// Method 3: Tracking an LLM model
// This wraps a language model to track all its interactions
const { ChatOpenAI } = require("langchain/chat_models");

const llm = new ChatOpenAI({
    modelName: "gpt-4",             // The LLM model to track
    temperature: 0.7
});

// Track the model's interactions
const trackedLLM = async (prompt) => {
    try {
        const response = await llm.call(prompt);
        await captureModel({
            modelId: "gpt4-chat",    // Unique identifier for this model
            requestBody: prompt,
            responseBody: response
        });
        return response;
    } catch (error) {
        await captureModel({
            modelId: "gpt4-chat",
            requestBody: prompt,
            responseBody: { error: error.message },
            error: true
        });
        throw error;
    }
};

// Method 4: Tracking a tool
// This wraps a tool to track all its executions
const searchDatabase = async (query) => {
    // Database search logic
    return results;
};

const trackedTool = traceAgentNode({
    agentNodeId: "db-search",       // Unique identifier from config
    callback: searchDatabase
});
```

**When to use each method:**
- **`captureAgentNode`** - Direct manual tracking of individual component executions (LLMs/Tools)
- **`traceAgentNode`** - For wrapping reusable functions (both async and sync)
- **`captureModel`** - For tracking individual LLM model interactions
- **`startAgentTracing`** - For wrapping the main agent function

<Callout type="tip">
  **Key principle:** The `agentNodeId` parameter must match the `slug` in your `handit.config.json` file for proper dashboard visualization.
</Callout>
</Tabs.Tab>
</Tabs>

## Best Practices for Production

<Steps>
### Secure Configuration
- Store your API key as an environment variable, never in code
- Use a single initialization point for the tracker across your application
- Keep your `handit.config.json` file version controlled with your code

### Smart Wrapping Strategy
- **Always wrap** your main agent function (the entry point)
- **Wrap all important nodes** in your agent pipeline (LLMs, tools, key functions)
- **Don't wrap** library functions, setup code, or utility functions
- **Focus on business logic** that you want to observe and debug

### Error Handling
- Let errors propagate naturally through your code
- Handit.ai automatically captures error details, stack traces, and context
- Don't try to handle tracing errors - the SDK is designed to be fail-safe

### Performance Considerations
- Use async/await patterns for better performance
- Keep your node functions focused and efficient
- The tracing overhead is minimal but measure if you have high-throughput requirements
</Steps>

<Callout type="warning">
  **Production tip:** Start with tracing your main workflows, then gradually add more detailed tracing as needed. Too much tracing can create noiseâ€”focus on what matters most for debugging and optimization.
</Callout>

## Complete Example: Invoice Processing Agent

Let's see how this all comes together with a real-world example. This invoice processing agent demonstrates all the concepts in action.

<Tabs items={['Python', 'JavaScript']}>
<Tabs.Tab>
**Step 1:** Set up your environment and API key:

```python filename="setup.py"
# setup.py
import os
from dotenv import load_dotenv
from handit import HanditTracker

# Load environment variables from .env file
load_dotenv()

# Initialize the tracker with your API key
tracker = HanditTracker()
tracker.config(api_key=os.getenv("HANDIT_API_KEY"))

# Export the tracker for use in other files
__all__ = ['tracker']
```

**Step 2:** The `handit.config.json` file for this example:

```json filename="handit.config.json"
{
  "agent": {
    "name": "Invoice Processing Assistant",
    "slug": "invoice-assistant",
    "description": "AI-powered invoice processing and analysis system"
  },
  "nodes": [
    {
      "name": "Vector Search",
      "slug": "vector-search",
      "type": "model",
      "problem_type": "retrieval",
      "description": "Searches for similar historical invoices",
      "next_nodes": ["pattern-analyzer"]
    },
    {
      "name": "Pattern Analyzer",
      "slug": "pattern-analyzer",
      "type": "model",
      "problem_type": "analysis",
      "description": "Analyzes patterns in similar invoices",
      "next_nodes": ["llm-generator"]
    },
    {
      "name": "LLM Generator",
      "slug": "llm-generator",
      "type": "model",
      "problem_type": "generation",
      "description": "Generates insights and recommendations",
      "next_nodes": []
    }
  ],
  "settings": {
    "max_retries": 3,
    "timeout": 30,
    "cache_enabled": true
  }
}
```

**Step 3:** Here's the complete invoice processing agent:

```python filename="invoice_agent.py"
from typing import Dict, List, Optional
from datetime import datetime
import json
from setup import tracker  # Import the configured tracker

class InvoiceProcessor:
    """
    A class to process and analyze invoices using AI.
    This agent uses vector search to find similar invoices and LLM to generate insights.
    """
    def __init__(self, vector_store, llm_model):
        """
        Initialize the processor with required services.
        
        Args:
            vector_store: A vector database instance for similarity search
            llm_model: An LLM model instance for generating insights
        """
        self.vector_store = vector_store
        self.llm_model = llm_model

    @tracker.start_agent_tracing(key="invoice-assistant")
    async def process_invoice(self, invoice_data: Dict) -> Dict:
        """
        Main method to process an invoice. This is the entry point for the agent.
        The @tracker.start_agent_tracing decorator ensures all operations are traced.
        
        Args:
            invoice_data: Dictionary containing invoice information
                Required fields: invoice_number, amount, date, vendor
        
        Returns:
            Dict containing processing results and recommendations
        """
        try:
            # Step 1: Validate the input data
            validated_data = await self._validate_invoice(invoice_data)
            
            # Step 2: Find similar historical invoices
            similar_invoices = await tracker.trace_agent_node_func(
                self._search_similar_invoices,
                validated_data,
                key="vector-search"  # This key must match the slug in handit.config.json
            )
            
            # Step 3: Analyze patterns in similar invoices
            analysis = await tracker.trace_agent_node_func(
                self._analyze_invoice_patterns,
                similar_invoices,
                key="pattern-analyzer"  # This key must match the slug in handit.config.json
            )
            
            # Step 4: Generate recommendations using LLM
            response = await tracker.trace_agent_node_func(
                self._generate_recommendations,
                {
                    "invoice": validated_data,
                    "similar_invoices": similar_invoices,
                    "analysis": analysis
                },
                key="llm-generator"  # This key must match the slug in handit.config.json
            )
            
            # Return successful response with timestamp
            return {
                "status": "success",
                "data": response,
                "timestamp": datetime.now().isoformat()
            }
            
        except Exception as e:
            # Return error response with details
            return {
                "status": "error",
                "error": str(e),
                "timestamp": datetime.now().isoformat()
            }

    async def _validate_invoice(self, invoice_data: Dict) -> Dict:
        """
        Validate the invoice data structure and required fields.
        
        Args:
            invoice_data: Raw invoice data dictionary
        
        Returns:
            Validated invoice data
        
        Raises:
            ValueError: If required fields are missing
        """
        required_fields = ["invoice_number", "amount", "date", "vendor"]
        for field in required_fields:
            if field not in invoice_data:
                raise ValueError(f"Missing required field: {field}")
        return invoice_data

    async def _search_similar_invoices(self, invoice_data: Dict) -> List[Dict]:
        """
        Search for similar invoices in the vector store.
        Uses semantic search to find invoices with similar characteristics.
        
        Args:
            invoice_data: Validated invoice data
        
        Returns:
            List of similar invoice metadata
        """
        # Construct a semantic search query
        query = f"Invoice from {invoice_data['vendor']} for {invoice_data['amount']}"
        results = await self.vector_store.similarity_search(
            query,
            k=5,  # Number of similar invoices to retrieve
            filter={"vendor": invoice_data["vendor"]}  # Filter by same vendor
        )
        return [doc.metadata for doc in results]

    async def _analyze_invoice_patterns(self, similar_invoices: List[Dict]) -> Dict:
        """
        Analyze patterns in similar invoices to identify trends.
        
        Args:
            similar_invoices: List of similar invoice metadata
        
        Returns:
            Dictionary containing analysis results
        """
        # Calculate average amount and frequency
        total_amount = sum(inv["amount"] for inv in similar_invoices)
        avg_amount = total_amount / len(similar_invoices)
        
        # Determine trend based on recent invoices
        return {
            "average_amount": avg_amount,
            "frequency": len(similar_invoices),
            "trend": "increasing" if avg_amount > total_amount / 2 else "decreasing"
        }

    async def _generate_recommendations(self, context: Dict) -> Dict:
        """
        Generate recommendations using the LLM model.
        
        Args:
            context: Dictionary containing invoice data, similar invoices, and analysis
        
        Returns:
            Dictionary containing recommendations and confidence score
        """
        # Construct a detailed prompt for the LLM
        prompt = f"""
        Analyze this invoice and provide recommendations:
        Invoice: {json.dumps(context['invoice'])}
        Similar Invoices: {json.dumps(context['similar_invoices'])}
        Analysis: {json.dumps(context['analysis'])}
        """
        
        # Generate recommendations using the LLM
        response = await self.llm_model.generate(prompt)
        return {
            "recommendations": response,
            "confidence_score": 0.95  # Confidence score for the recommendations
        }
```
</Tabs.Tab>
<Tabs.Tab>
**Step 1:** Set up your environment and API key:

```javascript filename="setup.js"
// setup.js
require('dotenv').config();
const { config } = require('@handit.ai/node');

// Configure Handit.ai with your API key
config({ 
    apiKey: process.env.HANDIT_API_KEY,
    // Optional: Configure custom endpoints
    trackingUrl: process.env.HANDIT_TRACKING_URL,
    performanceUrl: process.env.HANDIT_PERFORMANCE_URL
});

module.exports = { config };
```

**Step 2:** The `handit.config.json` file for this example:

```json filename="handit.config.json"
{
  "agent": {
    "name": "Invoice Processing Assistant",
    "slug": "invoice-assistant",
    "description": "AI-powered invoice processing and analysis system"
  },
  "nodes": [
    {
      "name": "Vector Search",
      "slug": "vector-search",
      "type": "model",
      "problem_type": "retrieval",
      "description": "Searches for similar historical invoices",
      "next_nodes": ["pattern-analyzer"]
    },
    {
      "name": "Pattern Analyzer",
      "slug": "pattern-analyzer",
      "type": "model",
      "problem_type": "analysis",
      "description": "Analyzes patterns in similar invoices",
      "next_nodes": ["llm-generator"]
    },
    {
      "name": "LLM Generator",
      "slug": "llm-generator",
      "type": "model",
      "problem_type": "generation",
      "description": "Generates insights and recommendations",
      "next_nodes": []
    }
  ],
  "settings": {
    "max_retries": 3,
    "timeout": 30,
    "cache_enabled": true
  }
}
```

**Step 3:** Here's the complete invoice processing agent:

```javascript filename="invoice_agent.js"
const { startAgentTracing, traceAgentNode } = require('@handit.ai/node');
require('./setup');  // Import the configuration

/**
 * InvoiceProcessor class for processing and analyzing invoices using AI.
 * This agent uses vector search to find similar invoices and LLM to generate insights.
 */
class InvoiceProcessor {
    /**
     * Initialize the processor with required services.
     * @param {Object} vectorStore - A vector database instance for similarity search
     * @param {Object} llmModel - An LLM model instance for generating insights
     */
    constructor(vectorStore, llmModel) {
        this.vectorStore = vectorStore;
        this.llmModel = llmModel;
    }

    /**
     * Main method to process an invoice. This is the entry point for the agent.
     * The startAgentTracing wrapper ensures all operations are traced.
     * @param {Object} invoiceData - Invoice information
     * @returns {Promise<Object>} Processing results and recommendations
     */
    processInvoice = startAgentTracing(async (invoiceData) => {
        try {
            // Step 1: Validate the input data
            const validatedData = await this._validateInvoice(invoiceData);
            
            // Step 2: Find similar historical invoices
            const searchNode = traceAgentNode({
                agentNodeId: "vector-search",  // Must match slug in handit.config.json
                callback: this._searchSimilarInvoices.bind(this)
            });
            const similarInvoices = await searchNode(validatedData);
            
            // Step 3: Analyze patterns in similar invoices
            const analyzeNode = traceAgentNode({
                agentNodeId: "pattern-analyzer",  // Must match slug in handit.config.json
                callback: this._analyzeInvoicePatterns.bind(this)
            });
            const analysis = await analyzeNode(similarInvoices);
            
            // Step 4: Generate recommendations using LLM
            const generateNode = traceAgentNode({
                agentNodeId: "llm-generator",  // Must match slug in handit.config.json
                callback: this._generateRecommendations.bind(this)
            });
            const response = await generateNode({
                invoice: validatedData,
                similarInvoices,
                analysis
            });
            
            // Return successful response with timestamp
            return {
                status: "success",
                data: response,
                timestamp: new Date().toISOString()
            };
            
        } catch (error) {
            // Return error response with details
            return {
                status: "error",
                error: error.message,
                timestamp: new Date().toISOString()
            };
        }
    });

    /**
     * Validate the invoice data structure and required fields.
     * @param {Object} invoiceData - Raw invoice data
     * @returns {Promise<Object>} Validated invoice data
     * @throws {Error} If required fields are missing
     */
    async _validateInvoice(invoiceData) {
        const requiredFields = ["invoiceNumber", "amount", "date", "vendor"];
        for (const field of requiredFields) {
            if (!invoiceData[field]) {
                throw new Error(`Missing required field: ${field}`);
            }
        }
        return invoiceData;
    }

    /**
     * Search for similar invoices in the vector store.
     * Uses semantic search to find invoices with similar characteristics.
     * @param {Object} invoiceData - Validated invoice data
     * @returns {Promise<Array>} List of similar invoice metadata
     */
    async _searchSimilarInvoices(invoiceData) {
        // Construct a semantic search query
        const query = `Invoice from ${invoiceData.vendor} for ${invoiceData.amount}`;
        const results = await this.vectorStore.similaritySearch(
            query,
            5,  // Number of similar invoices to retrieve
            { filter: { vendor: invoiceData.vendor } }  // Filter by same vendor
        );
        return results.map(doc => doc.metadata);
    }

    /**
     * Analyze patterns in similar invoices to identify trends.
     * @param {Array} similarInvoices - List of similar invoice metadata
     * @returns {Promise<Object>} Analysis results
     */
    async _analyzeInvoicePatterns(similarInvoices) {
        // Calculate average amount and frequency
        const totalAmount = similarInvoices.reduce((sum, inv) => sum + inv.amount, 0);
        const avgAmount = totalAmount / similarInvoices.length;
        
        // Determine trend based on recent invoices
        return {
            averageAmount: avgAmount,
            frequency: similarInvoices.length,
            trend: avgAmount > totalAmount / 2 ? "increasing" : "decreasing"
        };
    }

    /**
     * Generate recommendations using the LLM model.
     * @param {Object} context - Contains invoice data, similar invoices, and analysis
     * @returns {Promise<Object>} Recommendations and confidence score
     */
    async _generateRecommendations(context) {
        // Construct a detailed prompt for the LLM
        const prompt = `
        Analyze this invoice and provide recommendations:
        Invoice: ${JSON.stringify(context.invoice)}
        Similar Invoices: ${JSON.stringify(context.similarInvoices)}
        Analysis: ${JSON.stringify(context.analysis)}
        `;
        
        // Generate recommendations using the LLM
        const response = await this.llmModel.generate(prompt);
        return {
            recommendations: response,
            confidenceScore: 0.95  // Confidence score for the recommendations
        };
    }
}

// Usage example with sample data
const processor = new InvoiceProcessor(vectorStore, llmModel);
const result = await processor.processInvoice({
    invoiceNumber: "INV-2024-001",
    amount: 1500.00,
    date: "2024-03-15",
    vendor: "Tech Supplies Inc",
    items: [
        { description: "Laptop", quantity: 2, price: 750.00 }
    ]
});
```
</Tabs.Tab>
</Tabs>

## What's Next?

<Callout type="success">
  **Congratulations!** ðŸŽ‰ You now have complete observability into your AI agent. Every LLM call, tool execution, and operation is being captured with full context.
</Callout>

**View Your Results in the Dashboard:**

![AI Agent Tracing Dashboard](/assets/overview/tracing.png)

**Now you can:**
- **Debug issues faster** - See exactly where and why your agent fails
- **Optimize performance** - Identify slow operations and bottlenecks  
- **Understand behavior** - View complete execution flows and decision paths
- **Monitor production** - Get alerts when things go wrong

**Ready to explore more?**

- Learn about [Advanced Tracing Features](/tracing/tracing_features/overview) for comprehensive monitoring
- Explore [Agent Tracing](/tracing/tracing_features/agent) for end-to-end workflow tracking
- Check [LLM Node Tracing](/tracing/tracing_features/llm_node) for AI model optimization

*Your AI agents are no longer black boxesâ€”they're fully observable, debuggable, and optimizable systems.*
