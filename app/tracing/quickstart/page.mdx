import { Callout } from "nextra/components"
import { Steps } from "nextra/components"
import { Tabs } from "nextra/components"
import { Cards } from 'nextra/components'

# Quickstart Guide: Tracing with Handit.ai

This guide will help you get started with Handit.ai's tracing capabilities for monitoring your AI application. Handit.ai automatically tracks and monitors all function executions (sync and async) for your LLM nodes and tools, capturing inputs, outputs, errors, and context.



## Install
<Tabs items={['Python', 'JavaScript']}>
<Tabs.Tab>
```bash filename="terminal"
pip install -U "handit-sdk>=1.9.0"
```
</Tabs.Tab>
<Tabs.Tab>
```bash filename="terminal"
npm install @handit.ai/node
```
</Tabs.Tab>
</Tabs>

## Setup API Key
<Tabs items={['Python', 'JavaScript']}>
<Tabs.Tab>
First, create a `handit_service.py` file to initialize the tracker:

```python filename="handit_service.py"
# handit_service.py
from handit import HanditTracker

tracker = HanditTracker()
tracker.config(api_key="your-api-key")
```

Import the tracker in your agent code:

```python filename="agent_code.py"
from handit_service import tracker
```
</Tabs.Tab>
<Tabs.Tab>
Initialize Handit.ai in your entry file (e.g., `index.js` or `server.js`):

```javascript filename="index.js"
import { config } from '@handit.ai/node';

config({ apiKey: "your-api-key" });
```

Import the required functions in your agent code:

```javascript filename="agent.js"
import { startAgentTracing, traceAgentNode } from '@handit.ai/node';
```
</Tabs.Tab>
</Tabs>


## Configuration File

Before implementing tracing, you need to set up your configuration in the Handit.ai Dashboard:

1. Create a new agent in the Dashboard
2. Define your nodes (LLMs, tools, etc.)
3. Download the `handit.config.json` file

The `handit.config.json` file defines your agent's structure and its components. Each node needs a unique `slug` that you'll use when implementing tracing in your code.

Here's an example configuration:

```json filename="handit.config.json"
{
  "agent": {
    "name": "My AI Agent",          // Display name for your agent
    "slug": "my-ai-id",            // Unique identifier for your agent
    "description": "Main orchestration logic"
  },
  "nodes": [
    {
      "name": "Vector Search",      // Display name for the node
      "slug": "vector-search",      // Unique identifier used in tracing
      "type": "model",             // Node type (model, tool, etc.)
      "problem_type": "retrieval",  // Type of problem it solves
      "description": "Searches similar documents",
      "next_nodes": ["llm-generator"]  // Connected nodes in the workflow
    },
    {
      "name": "LLM Generator",
      "slug": "llm-generator",
      "type": "model",
      "problem_type": "generation",
      "description": "Generates responses using LLM",
      "next_nodes": []
    }
  ]
}
```

When implementing tracing, you'll use these `slug` values to identify your nodes:

```python
# Using the vector-search slug from config
@tracker.trace_agent_node("vector-search")
async def search_documents(query: str):
    # Your search logic here
    return results

# Using the llm-generator slug from config
@tracker.trace_agent_node("llm-generator")
async def generate_response(context: str):
    # Your generation logic here
    return response
```

## Tracing Your Agent

<Tabs items={['Python', 'JavaScript']}>
<Tabs.Tab>
1. Wrap your main agent function (The main API endpoint processing requests or the main function that executes the entire workflow) with the `@tracker.start_agent_tracing()` decorator:

```python {3} filename="agent_function.py"
from handit_service import tracker

@tracker.start_agent_tracing()
async def process_message(self, user_message: str, conversation_history: list):
    # Process the user message and generate a response
    try:
        # Analyze the message intent
        intent = await self.analyze_intent(user_message)
        
        # Generate response based on intent
        response = await self.generate_response(intent, conversation_history)
        
        return {
            "response": response,
            "intent": intent,
            "status": "success"
        }
    except Exception as e:
        return {
            "error": str(e),
            "status": "error"
        }
```

2. Wrap individual nodes (tools/LLMs) using one of these methods:

```python filename="node_tracing.py"
# Method 1: Using trace_agent_node_func for async functions
# This is useful for one-off async function calls that need tracing
result = await tracker.trace_agent_node_func(
    search_documents,           # func: The async function to trace
    query="customer support",   # *args: Positional arguments for the function
    limit=5,                    # **kwargs: Keyword arguments for the function
    key="document-search"       # key: Unique identifier for this node in analytics
)

# Method 2: Using trace_agent_node_func_sync for sync functions
# This is useful for one-off sync function calls that need tracing
result = tracker.trace_agent_node_func_sync(
    process_text,              # func: The sync function to trace
    text="Hello world",        # *args: Positional arguments for the function
    language="en",             # **kwargs: Keyword arguments for the function
    key="text-processor"       # key: Unique identifier for this node in analytics
)

# Method 3: Using trace_agent_node decorator for async functions
# This is useful for reusable async functions that need tracing
@tracker.trace_agent_node("vector-search")  # agent_node_id: Unique identifier for this node
async def search_similar_documents(query: str, top_k: int = 5):
    # Your vector search logic here
    return results

# Method 4: Using trace_agent_node decorator for sync functions
# This is useful for reusable sync functions that need tracing
@tracker.trace_agent_node("text-processor")  # agent_node_id: Unique identifier for this node
def process_text(text: str, language: str = "en"):
    # Your text processing logic here
    return processed_text

# Method 5: Tracking an LLM model
# This wraps a language model to track all its interactions
from langchain.chat_models import ChatOpenAI

llm = ChatOpenAI(
    model_name="gpt-4",        # model: The LLM model to track
    temperature=0.7
)
tracked_llm = tracker.track_model(
    llm,                       # model: The model instance to track
    "gpt4-chat"               # model_id: Unique identifier for this model
)

# Method 6: Tracking a tool
# This wraps a tool to track all its executions
from langchain.tools import Tool

def search_database(query: str):
    # Database search logic
    return results

search_tool = Tool(
    name="database-search",    # tool: The tool to track
    func=search_database
)
tracked_tool = tracker.track_tool(
    search_tool,              # tool: The tool instance to track
    "db-search"              # tool_id: Unique identifier for this tool
)
```

Each method has its use case:
- `trace_agent_node_func`: For one-off async function calls
- `trace_agent_node_func_sync`: For one-off sync function calls
- `trace_agent_node` decorator: For reusable async/sync functions
- `track_model`: For tracking LLM models and their interactions
- `track_tool`: For tracking tools, RAG systems, and API calls

The `key` parameter is used to identify the node in your configuration and analytics.
</Tabs.Tab>
<Tabs.Tab>
1. Wrap your main agent function (the main API endpoint processing requests or the main function that executes the entire workflow) with `startAgentTracing`:

```javascript filename="agent_function.js"
const { startAgentTracing } = require('@handit.ai/node');

const processMessage = startAgentTracing(async (userMessage, conversationHistory) => {
    try {
        // Analyze the message intent
        const intent = await analyzeIntent(userMessage);
        
        // Generate response based on intent
        const response = await generateResponse(intent, conversationHistory);
        
        return {
            response,
            intent,
            status: "success"
        };
    } catch (error) {
        return {
            error: error.message,
            status: "error"
        };
    }
});
```

2. Wrap individual nodes using one of these methods:

```javascript filename="node_tracing.js"
const { traceAgentNode, captureModel } = require('@handit.ai/node');

// Method 1: Using traceAgentNode for async functions
// This is useful for reusable async functions that need tracing
const searchDocuments = traceAgentNode({
    agentNodeId: "vector-search",    // Unique identifier from config
    callback: async (query, limit = 5) => {
        // Your vector search logic here
        return results;
    }
});

// Method 2: Using traceAgentNode for sync functions
// This is useful for reusable sync functions that need tracing
const processText = traceAgentNode({
    agentNodeId: "text-processor",   // Unique identifier from config
    callback: (text, language = "en") => {
        // Your text processing logic here
        return processedText;
    }
});

// Method 3: Tracking an LLM model
// This wraps a language model to track all its interactions
const { ChatOpenAI } = require("langchain/chat_models");

const llm = new ChatOpenAI({
    modelName: "gpt-4",             // The LLM model to track
    temperature: 0.7
});

// Track the model's interactions
const trackedLLM = async (prompt) => {
    try {
        const response = await llm.call(prompt);
        await captureModel({
            modelId: "gpt4-chat",    // Unique identifier for this model
            requestBody: prompt,
            responseBody: response
        });
        return response;
    } catch (error) {
        await captureModel({
            modelId: "gpt4-chat",
            requestBody: prompt,
            responseBody: { error: error.message },
            error: true
        });
        throw error;
    }
};

// Method 4: Tracking a tool
// This wraps a tool to track all its executions
const searchDatabase = async (query) => {
    // Database search logic
    return results;
};

const trackedTool = traceAgentNode({
    agentNodeId: "db-search",       // Unique identifier from config
    callback: searchDatabase
});
```

Each method has its use case:
- `traceAgentNode`: For wrapping reusable functions (both async and sync)
- `captureModel`: For tracking individual LLM model interactions
- `startAgentTracing`: For wrapping the main agent function

The `agentNodeId` parameter must match the `slug` in your `handit.config.json` file.
</Tabs.Tab>
</Tabs>


## Best Practices

<Steps>
 ### Centralize Configuration
   - Keep your API key in a secure environment variable
   - Use a single initialization point for the tracker

### Proper Wrapping
   - Always wrap the main agent function
   - Wrap all nodes in your agent pipeline
   - Don't wrap library functions or setup code

### Error Handling
   - Let errors propagate naturally
   - Handit.ai will automatically capture error details

### Performance
   - Use async/await for better performance
   - Keep node functions focused and efficient

</Steps>

## Example: Complete Agent

<Tabs items={['Python', 'JavaScript']}>
<Tabs.Tab>
First, set up your environment and API key:

```python filename="setup.py"
# setup.py
import os
from dotenv import load_dotenv
from handit import HanditTracker

# Load environment variables from .env file
load_dotenv()

# Initialize the tracker with your API key
tracker = HanditTracker()
tracker.config(api_key=os.getenv("HANDIT_API_KEY"))

# Export the tracker for use in other files
__all__ = ['tracker']
```

Create your `handit.config.json` file for this example:

```json filename="handit.config.json"
{
  "agent": {
    "name": "Invoice Processing Assistant",
    "slug": "invoice-assistant",
    "description": "AI-powered invoice processing and analysis system"
  },
  "nodes": [
    {
      "name": "Vector Search",
      "slug": "vector-search",
      "type": "model",
      "problem_type": "retrieval",
      "description": "Searches for similar historical invoices",
      "next_nodes": ["pattern-analyzer"]
    },
    {
      "name": "Pattern Analyzer",
      "slug": "pattern-analyzer",
      "type": "model",
      "problem_type": "analysis",
      "description": "Analyzes patterns in similar invoices",
      "next_nodes": ["llm-generator"]
    },
    {
      "name": "LLM Generator",
      "slug": "llm-generator",
      "type": "model",
      "problem_type": "generation",
      "description": "Generates insights and recommendations",
      "next_nodes": []
    }
  ],
  "settings": {
    "max_retries": 3,
    "timeout": 30,
    "cache_enabled": true
  }
}
```

Now, here's the complete invoice processing agent:

```python filename="invoice_agent.py"
from typing import Dict, List, Optional
from datetime import datetime
import json
from setup import tracker  # Import the configured tracker

class InvoiceProcessor:
    """
    A class to process and analyze invoices using AI.
    This agent uses vector search to find similar invoices and LLM to generate insights.
    """
    def __init__(self, vector_store, llm_model):
        """
        Initialize the processor with required services.
        
        Args:
            vector_store: A vector database instance for similarity search
            llm_model: An LLM model instance for generating insights
        """
        self.vector_store = vector_store
        self.llm_model = llm_model

    @tracker.start_agent_tracing(key="invoice-assistant")
    async def process_invoice(self, invoice_data: Dict) -> Dict:
        """
        Main method to process an invoice. This is the entry point for the agent.
        The @tracker.start_agent_tracing decorator ensures all operations are traced.
        
        Args:
            invoice_data: Dictionary containing invoice information
                Required fields: invoice_number, amount, date, vendor
        
        Returns:
            Dict containing processing results and recommendations
        """
        try:
            # Step 1: Validate the input data
            validated_data = await self._validate_invoice(invoice_data)
            
            # Step 2: Find similar historical invoices
            similar_invoices = await tracker.trace_agent_node_func(
                self._search_similar_invoices,
                validated_data,
                key="vector-search"  # This key must match the slug in handit.config.json
            )
            
            # Step 3: Analyze patterns in similar invoices
            analysis = await tracker.trace_agent_node_func(
                self._analyze_invoice_patterns,
                similar_invoices,
                key="pattern-analyzer"  # This key must match the slug in handit.config.json
            )
            
            # Step 4: Generate recommendations using LLM
            response = await tracker.trace_agent_node_func(
                self._generate_recommendations,
                {
                    "invoice": validated_data,
                    "similar_invoices": similar_invoices,
                    "analysis": analysis
                },
                key="llm-generator"  # This key must match the slug in handit.config.json
            )
            
            # Return successful response with timestamp
            return {
                "status": "success",
                "data": response,
                "timestamp": datetime.now().isoformat()
            }
            
        except Exception as e:
            # Return error response with details
            return {
                "status": "error",
                "error": str(e),
                "timestamp": datetime.now().isoformat()
            }

    async def _validate_invoice(self, invoice_data: Dict) -> Dict:
        """
        Validate the invoice data structure and required fields.
        
        Args:
            invoice_data: Raw invoice data dictionary
        
        Returns:
            Validated invoice data
        
        Raises:
            ValueError: If required fields are missing
        """
        required_fields = ["invoice_number", "amount", "date", "vendor"]
        for field in required_fields:
            if field not in invoice_data:
                raise ValueError(f"Missing required field: {field}")
        return invoice_data

    async def _search_similar_invoices(self, invoice_data: Dict) -> List[Dict]:
        """
        Search for similar invoices in the vector store.
        Uses semantic search to find invoices with similar characteristics.
        
        Args:
            invoice_data: Validated invoice data
        
        Returns:
            List of similar invoice metadata
        """
        # Construct a semantic search query
        query = f"Invoice from {invoice_data['vendor']} for {invoice_data['amount']}"
        results = await self.vector_store.similarity_search(
            query,
            k=5,  # Number of similar invoices to retrieve
            filter={"vendor": invoice_data["vendor"]}  # Filter by same vendor
        )
        return [doc.metadata for doc in results]

    async def _analyze_invoice_patterns(self, similar_invoices: List[Dict]) -> Dict:
        """
        Analyze patterns in similar invoices to identify trends.
        
        Args:
            similar_invoices: List of similar invoice metadata
        
        Returns:
            Dictionary containing analysis results
        """
        # Calculate average amount and frequency
        total_amount = sum(inv["amount"] for inv in similar_invoices)
        avg_amount = total_amount / len(similar_invoices)
        
        # Determine trend based on recent invoices
        return {
            "average_amount": avg_amount,
            "frequency": len(similar_invoices),
            "trend": "increasing" if avg_amount > total_amount / 2 else "decreasing"
        }

    async def _generate_recommendations(self, context: Dict) -> Dict:
        """
        Generate recommendations using the LLM model.
        
        Args:
            context: Dictionary containing invoice data, similar invoices, and analysis
        
        Returns:
            Dictionary containing recommendations and confidence score
        """
        # Construct a detailed prompt for the LLM
        prompt = f"""
        Analyze this invoice and provide recommendations:
        Invoice: {json.dumps(context['invoice'])}
        Similar Invoices: {json.dumps(context['similar_invoices'])}
        Analysis: {json.dumps(context['analysis'])}
        """
        
        # Generate recommendations using the LLM
        response = await self.llm_model.generate(prompt)
        return {
            "recommendations": response,
            "confidence_score": 0.95  # Confidence score for the recommendations
        }
```
</Tabs.Tab>
<Tabs.Tab>
First, set up your environment and API key:

```javascript filename="setup.js"
// setup.js
require('dotenv').config();
const { config } = require('@handit.ai/node');

// Configure Handit.ai with your API key
config({ 
    apiKey: process.env.HANDIT_API_KEY,
    // Optional: Configure custom endpoints
    trackingUrl: process.env.HANDIT_TRACKING_URL,
    performanceUrl: process.env.HANDIT_PERFORMANCE_URL
});

module.exports = { config };
```

The `handit.config.json` file for this example:

```json filename="handit.config.json"
{
  "agent": {
    "name": "Invoice Processing Assistant",
    "slug": "invoice-assistant",
    "description": "AI-powered invoice processing and analysis system"
  },
  "nodes": [
    {
      "name": "Vector Search",
      "slug": "vector-search",
      "type": "model",
      "problem_type": "retrieval",
      "description": "Searches for similar historical invoices",
      "next_nodes": ["pattern-analyzer"]
    },
    {
      "name": "Pattern Analyzer",
      "slug": "pattern-analyzer",
      "type": "model",
      "problem_type": "analysis",
      "description": "Analyzes patterns in similar invoices",
      "next_nodes": ["llm-generator"]
    },
    {
      "name": "LLM Generator",
      "slug": "llm-generator",
      "type": "model",
      "problem_type": "generation",
      "description": "Generates insights and recommendations",
      "next_nodes": []
    }
  ],
  "settings": {
    "max_retries": 3,
    "timeout": 30,
    "cache_enabled": true
  }
}
```

Now, here's the complete invoice processing agent:

```javascript filename="invoice_agent.js"
const { startAgentTracing, traceAgentNode } = require('@handit.ai/node');
require('./setup');  // Import the configuration

/**
 * InvoiceProcessor class for processing and analyzing invoices using AI.
 * This agent uses vector search to find similar invoices and LLM to generate insights.
 */
class InvoiceProcessor {
    /**
     * Initialize the processor with required services.
     * @param {Object} vectorStore - A vector database instance for similarity search
     * @param {Object} llmModel - An LLM model instance for generating insights
     */
    constructor(vectorStore, llmModel) {
        this.vectorStore = vectorStore;
        this.llmModel = llmModel;
    }

    /**
     * Main method to process an invoice. This is the entry point for the agent.
     * The startAgentTracing wrapper ensures all operations are traced.
     * @param {Object} invoiceData - Invoice information
     * @returns {Promise<Object>} Processing results and recommendations
     */
    processInvoice = startAgentTracing(async (invoiceData) => {
        try {
            // Step 1: Validate the input data
            const validatedData = await this._validateInvoice(invoiceData);
            
            // Step 2: Find similar historical invoices
            const searchNode = traceAgentNode({
                agentNodeId: "vector-search",  // Must match slug in handit.config.json
                callback: this._searchSimilarInvoices.bind(this)
            });
            const similarInvoices = await searchNode(validatedData);
            
            // Step 3: Analyze patterns in similar invoices
            const analyzeNode = traceAgentNode({
                agentNodeId: "pattern-analyzer",  // Must match slug in handit.config.json
                callback: this._analyzeInvoicePatterns.bind(this)
            });
            const analysis = await analyzeNode(similarInvoices);
            
            // Step 4: Generate recommendations using LLM
            const generateNode = traceAgentNode({
                agentNodeId: "llm-generator",  // Must match slug in handit.config.json
                callback: this._generateRecommendations.bind(this)
            });
            const response = await generateNode({
                invoice: validatedData,
                similarInvoices,
                analysis
            });
            
            // Return successful response with timestamp
            return {
                status: "success",
                data: response,
                timestamp: new Date().toISOString()
            };
            
        } catch (error) {
            // Return error response with details
            return {
                status: "error",
                error: error.message,
                timestamp: new Date().toISOString()
            };
        }
    });

    /**
     * Validate the invoice data structure and required fields.
     * @param {Object} invoiceData - Raw invoice data
     * @returns {Promise<Object>} Validated invoice data
     * @throws {Error} If required fields are missing
     */
    async _validateInvoice(invoiceData) {
        const requiredFields = ["invoiceNumber", "amount", "date", "vendor"];
        for (const field of requiredFields) {
            if (!invoiceData[field]) {
                throw new Error(`Missing required field: ${field}`);
            }
        }
        return invoiceData;
    }

    /**
     * Search for similar invoices in the vector store.
     * Uses semantic search to find invoices with similar characteristics.
     * @param {Object} invoiceData - Validated invoice data
     * @returns {Promise<Array>} List of similar invoice metadata
     */
    async _searchSimilarInvoices(invoiceData) {
        // Construct a semantic search query
        const query = `Invoice from ${invoiceData.vendor} for ${invoiceData.amount}`;
        const results = await this.vectorStore.similaritySearch(
            query,
            5,  // Number of similar invoices to retrieve
            { filter: { vendor: invoiceData.vendor } }  // Filter by same vendor
        );
        return results.map(doc => doc.metadata);
    }

    /**
     * Analyze patterns in similar invoices to identify trends.
     * @param {Array} similarInvoices - List of similar invoice metadata
     * @returns {Promise<Object>} Analysis results
     */
    async _analyzeInvoicePatterns(similarInvoices) {
        // Calculate average amount and frequency
        const totalAmount = similarInvoices.reduce((sum, inv) => sum + inv.amount, 0);
        const avgAmount = totalAmount / similarInvoices.length;
        
        // Determine trend based on recent invoices
        return {
            averageAmount: avgAmount,
            frequency: similarInvoices.length,
            trend: avgAmount > totalAmount / 2 ? "increasing" : "decreasing"
        };
    }

    /**
     * Generate recommendations using the LLM model.
     * @param {Object} context - Contains invoice data, similar invoices, and analysis
     * @returns {Promise<Object>} Recommendations and confidence score
     */
    async _generateRecommendations(context) {
        // Construct a detailed prompt for the LLM
        const prompt = `
        Analyze this invoice and provide recommendations:
        Invoice: ${JSON.stringify(context.invoice)}
        Similar Invoices: ${JSON.stringify(context.similarInvoices)}
        Analysis: ${JSON.stringify(context.analysis)}
        `;
        
        // Generate recommendations using the LLM
        const response = await this.llmModel.generate(prompt);
        return {
            recommendations: response,
            confidenceScore: 0.95  // Confidence score for the recommendations
        };
    }
}

// Usage example with sample data
const processor = new InvoiceProcessor(vectorStore, llmModel);
const result = await processor.processInvoice({
    invoiceNumber: "INV-2024-001",
    amount: 1500.00,
    date: "2024-03-15",
    vendor: "Tech Supplies Inc",
    items: [
        { description: "Laptop", quantity: 2, price: 750.00 }
    ]
});
```
</Tabs.Tab>
</Tabs>

## Next Steps

For more detailed information, check out our [full features](/tracing/tracing_features/overview).
