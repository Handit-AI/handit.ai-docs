---
title: 'Node Tracing Decorator'
sidebarTitle: 'Node Tracing Decorator'
---

import { Callout } from "nextra/components"
import { Steps } from "nextra/components"
import { Tabs } from "nextra/components"

# Node Tracing Decorator

Node Tracing provides an elegant solution for function-level tracing. When you control the function definition ―like a method that calls a model― this decorator provides a clean and explicit way to track operations. It's perfect for wrapping individual functions with minimal code changes.

<Callout type="info">
  Node Tracing is ideal for tracking individual components within your AI application, such as model calls, tool executions, or data processing functions.
</Callout>

## How It Works

Node Tracing creates a trace for individual function executions, allowing you to:

- Track specific function calls and their results
- Monitor performance of individual components
- Debug issues at the function level
- Correlate function executions with the broader workflow



## Implementation

<Tabs items={['Python', 'JavaScript']}>
  <Tabs.Tab>
    ```python filename="node_tracing.py"
    from handit_service import tracker

    # Basic usage with async function
    @tracker.trace_agent_node("vector-search")
    async def fetch_documents(query: str) -> list[str]:
        """
        Search for relevant documents using vector similarity.
        """
        # Your vector search implementation
        return docs

    # Basic usage with sync function
    @tracker.trace_agent_node("text-processor")
    def process_text(text: str) -> str:
        """
        Process and clean input text.
        """
        # Your text processing implementation
        return processed_text

    # With error handling
    @tracker.trace_agent_node("model-inference")
    async def run_inference(prompt: str) -> str:
        """
        Run model inference with proper error handling.
        """
        try:
            result = await model.generate(prompt)
            return result
        except Exception as e:
            logger.error(f"Inference error: {e}")
            raise
    ```
  </Tabs.Tab>
  <Tabs.Tab>
    ```javascript filename="node_tracing.js"
    const { traceAgentNode } = require('handit-service');

    // Basic usage with async function
    const fetchDocuments = traceAgentNode({
        agentNodeId: 'vector-search',
        callback: async (query) => {
            // Your vector search implementation
            return docs;
        }
    });

    // Basic usage with sync function
    const processText = traceAgentNode({
        agentNodeId: 'text-processor',
        callback: (text) => {
            // Your text processing implementation
            return processedText;
        }
    });

    // With error handling
    const runInference = traceAgentNode({
        agentNodeId: 'model-inference',
        callback: async (prompt) => {
            try {
                const result = await model.generate(prompt);
                return result;
            } catch (error) {
                logger.error(`Inference error: ${error}`);
                throw error;
            }
        }
    });
    ```
  </Tabs.Tab>
</Tabs>

## Common Use Cases

### 1. Model Calls

<Tabs items={['Python', 'JavaScript']}>
  <Tabs.Tab>
    ```python filename="model_calls.py"
    @tracker.trace_agent_node("llm-inference")
    async def generate_response(prompt: str, model_config: dict) -> str:
        """
        Generate response using LLM with specific configuration.
        """
        response = await llm.generate(
            prompt=prompt,
            temperature=model_config.get("temperature", 0.7),
            max_tokens=model_config.get("max_tokens", 100)
        )
        return response

    @tracker.trace_agent_node("embedding-generation")
    async def generate_embeddings(text: str) -> list[float]:
        """
        Generate embeddings for input text.
        """
        embeddings = await embedding_model.embed(text)
        return embeddings
    ```
  </Tabs.Tab>
  <Tabs.Tab>
    ```javascript filename="model_calls.js"
    const generateResponse = traceAgentNode({
        agentNodeId: 'llm-inference',
        callback: async (prompt, modelConfig) => {
            const response = await llm.generate({
                prompt,
                temperature: modelConfig.temperature || 0.7,
                maxTokens: modelConfig.maxTokens || 100
            });
            return response;
        }
    });

    const generateEmbeddings = traceAgentNode({
        agentNodeId: 'embedding-generation',
        callback: async (text) => {
            const embeddings = await embeddingModel.embed(text);
            return embeddings;
        }
    });
    ```
  </Tabs.Tab>
</Tabs>

### 2. Tool Executions

<Tabs items={['Python', 'JavaScript']}>
  <Tabs.Tab>
    ```python filename="tool_executions.py"
    @tracker.trace_agent_node("web-search")
    async def search_web(query: str) -> list[dict]:
        """
        Execute web search and return results.
        """
        results = await search_tool.execute(query)
        return results

    @tracker.trace_agent_node("data-processing")
    async def process_data(data: dict) -> dict:
        """
        Process and transform input data.
        """
        processed = await data_processor.transform(data)
        return processed
    ```
  </Tabs.Tab>
  <Tabs.Tab>
    ```javascript filename="tool_executions.js"
    const searchWeb = traceAgentNode({
        agentNodeId: 'web-search',
        callback: async (query) => {
            const results = await searchTool.execute(query);
            return results;
        }
    });

    const processData = traceAgentNode({
        agentNodeId: 'data-processing',
        callback: async (data) => {
            const processed = await dataProcessor.transform(data);
            return processed;
        }
    });
    ```
  </Tabs.Tab>
</Tabs>

### 3. Data Processing

<Tabs items={['Python', 'JavaScript']}>
  <Tabs.Tab>
    ```python filename="data_processing.py"
    @tracker.trace_agent_node("text-extraction")
    async def extract_text(document: bytes) -> str:
        """
        Extract text from document bytes.
        """
        text = await document_processor.extract(document)
        return text

    @tracker.trace_agent_node("data-validation")
    def validate_data(data: dict) -> bool:
        """
        Validate input data against schema.
        """
        return validator.validate(data)
    ```
  </Tabs.Tab>
  <Tabs.Tab>
    ```javascript filename="data_processing.js"
    const extractText = traceAgentNode({
        agentNodeId: 'text-extraction',
        callback: async (document) => {
            const text = await documentProcessor.extract(document);
            return text;
        }
    });

    const validateData = traceAgentNode({
        agentNodeId: 'data-validation',
        callback: (data) => {
            return validator.validate(data);
        }
    });
    ```
  </Tabs.Tab>
</Tabs>

## Best Practices

1. **Meaningful Node IDs**
   - Use descriptive names for your nodes
   - Include version information if applicable
   - Make IDs consistent across environments

2. **Error Handling**
   - Implement proper error handling
   - Let errors propagate naturally
   - Include error context in traces

3. **Performance Monitoring**
   - Track execution time
   - Monitor resource usage
   - Identify bottlenecks

4. **Data Sanitization**
   - Remove sensitive information
   - Sanitize input/output data
   - Handle large payloads appropriately

<Callout type="warning">
  Always implement proper error handling in your traced functions to ensure errors are properly tracked and reported.
</Callout>

## Advanced Usage

### 1. Custom Context

<Tabs items={['Python', 'JavaScript']}>
  <Tabs.Tab>
    ```python filename="custom_context.py"
    @tracker.trace_agent_node("custom-processor")
    async def process_with_context(data: dict, context: dict) -> dict:
        """
        Process data with custom context information.
        """
        # Add context to processing
        result = await processor.process(data, context)
        return result
    ```
  </Tabs.Tab>
  <Tabs.Tab>
    ```javascript filename="custom_context.js"
    const processWithContext = traceAgentNode({
        agentNodeId: 'custom-processor',
        callback: async (data, context) => {
            // Add context to processing
            const result = await processor.process(data, context);
            return result;
        }
    });
    ```
  </Tabs.Tab>
</Tabs>

### 2. Batch Processing

<Tabs items={['Python', 'JavaScript']}>
  <Tabs.Tab>
    ```python filename="batch_processing.py"
    @tracker.trace_agent_node("batch-processor")
    async def process_batch(items: list) -> list:
        """
        Process a batch of items with tracking.
        """
        results = []
        for item in items:
            result = await process_item(item)
            results.append(result)
        return results
    ```
  </Tabs.Tab>
  <Tabs.Tab>
    ```javascript filename="batch_processing.js"
    const processBatch = traceAgentNode({
        agentNodeId: 'batch-processor',
        callback: async (items) => {
            const results = [];
            for (const item of items) {
                const result = await processItem(item);
                results.push(result);
            }
            return results;
        }
    });
    ```
  </Tabs.Tab>
</Tabs>

<Callout type="info">
  Node Tracing is particularly useful for tracking individual components within your AI application, providing granular visibility into their behavior and performance.
</Callout>

<Callout type="success">
  By using Node Tracing effectively, you can gain deep insights into your application's components and optimize their performance.
</Callout>
