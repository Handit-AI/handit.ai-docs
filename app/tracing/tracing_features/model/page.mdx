---
title: 'Model Tracing'
sidebarTitle: 'Model Tracing'
---

import { Callout } from "nextra/components"
import { Steps } from "nextra/components"
import { Tabs } from "nextra/components"

# Model Tracing

Model Tracing is an essential component that keeps a detailed record of every interaction with your AI models, helping you understand their behavior and optimize their performance. It provides comprehensive tracking for LLMs, embedding models, and other AI components.

<Callout type="info">
  Model Tracing is ideal when you have an existing LLM object that implements `__call__` (like ChatOpenAI, GPT, etc.) and want to transparently intercept all its invocations.
</Callout>

## How It Works

Model Tracing wraps your AI models to:

- Track all model inputs and outputs
- Monitor performance metrics
- Capture error cases
- Maintain detailed logs of model interactions

## Implementation

<Tabs items={['Python', 'JavaScript']}>
  <Tabs.Tab>
    ```python filename="model_tracing.py"
    from langchain_openai import ChatOpenAI
    from handit_service import tracker
    import logging
    from typing import Any, Dict, List, Optional

    # Basic usage with OpenAI model
    llm = ChatOpenAI(model="gpt-4-mini")
    llm = tracker.track_model(llm, "gpt4-mini-production")

    # Usage with error handling
    async def generate_response(messages: List[Dict[str, str]]) -> str:
        try:
            response = await llm.invoke(messages)
            return response
        except Exception as e:
            logging.error(f"Error generating response: {str(e)}")
            raise

    # Example with multiple models
    embedding_model = OpenAIEmbeddings()
    embedding_model = tracker.track_model(embedding_model, "embeddings-production")

    # Usage with custom parameters
    async def get_embeddings(texts: List[str]) -> List[List[float]]:
        try:
            embeddings = await embedding_model.aembed_documents(texts)
            return embeddings
        except Exception as e:
            logging.error(f"Error generating embeddings: {str(e)}")
            raise
    ```
  </Tabs.Tab>
  <Tabs.Tab>
    ```javascript filename="model_tracing.js"
    const { trackModel } = require('handit-service');
    const { OpenAI } = require('langchain/llms/openai');
    const logger = require('./logger');

    // Basic usage with OpenAI model
    const llm = new OpenAI({ modelName: 'gpt-4-mini' });
    const trackedLlm = trackModel(llm, 'gpt4-mini-production');

    // Usage with error handling
    const generateResponse = async (messages) => {
        try {
            const response = await trackedLlm.call(messages);
            return response;
        } catch (error) {
            logger.error(`Error generating response: ${error.message}`);
            throw error;
        }
    };

    // Example with multiple models
    const embeddingModel = new OpenAIEmbeddings();
    const trackedEmbeddingModel = trackModel(embeddingModel, 'embeddings-production');

    // Usage with custom parameters
    const getEmbeddings = async (texts) => {
        try {
            const embeddings = await trackedEmbeddingModel.embedDocuments(texts);
            return embeddings;
        } catch (error) {
            logger.error(`Error generating embeddings: ${error.message}`);
            throw error;
        }
    };
    ```
  </Tabs.Tab>
</Tabs>

## Common Use Cases

### 1. Chat Model Tracking

<Tabs items={['Python', 'JavaScript']}>
  <Tabs.Tab>
    ```python filename="chat_tracking.py"
    from langchain_openai import ChatOpenAI
    from handit_service import tracker
    from typing import List, Dict, Any
    import logging

    # Chat model tracking with conversation history
    class ChatBot:
        def __init__(self, model_name: str = "gpt-4-mini"):
            self.llm = ChatOpenAI(model=model_name)
            self.llm = tracker.track_model(
                self.llm,
                f"chat-{model_name}-production"
            )
            self.conversation_history: List[Dict[str, str]] = []

        async def chat(self, message: str) -> str:
            try:
                # Add user message to history
                self.conversation_history.append({
                    "role": "user",
                    "content": message
                })

                # Generate response
                response = await self.llm.invoke(self.conversation_history)

                # Add assistant response to history
                self.conversation_history.append({
                    "role": "assistant",
                    "content": response
                })

                return response
            except Exception as e:
                logging.error(f"Chat error: {str(e)}")
                raise

    # Usage
    async def main():
        chatbot = ChatBot()
        response = await chatbot.chat("Hello, how are you?")
        print(response)
    ```
  </Tabs.Tab>
  <Tabs.Tab>
    ```javascript filename="chat_tracking.js"
    const { trackModel } = require('handit-service');
    const { ChatOpenAI } = require('langchain/chat_models/openai');
    const logger = require('./logger');

    // Chat model tracking with conversation history
    class ChatBot {
        constructor(modelName = 'gpt-4-mini') {
            this.llm = new ChatOpenAI({ modelName });
            this.llm = trackModel(
                this.llm,
                `chat-${modelName}-production`
            );
            this.conversationHistory = [];
        }

        async chat(message) {
            try {
                // Add user message to history
                this.conversationHistory.push({
                    role: 'user',
                    content: message
                });

                // Generate response
                const response = await this.llm.call(this.conversationHistory);

                // Add assistant response to history
                this.conversationHistory.push({
                    role: 'assistant',
                    content: response
                });

                return response;
            } catch (error) {
                logger.error(`Chat error: ${error.message}`);
                throw error;
            }
        }
    }

    // Usage
    const main = async () => {
        const chatbot = new ChatBot();
        const response = await chatbot.chat('Hello, how are you?');
        console.log(response);
    };
    ```
  </Tabs.Tab>
</Tabs>

### 2. Embedding Model Tracking

<Tabs items={['Python', 'JavaScript']}>
  <Tabs.Tab>
    ```python filename="embedding_tracking.py"
    from langchain_openai import OpenAIEmbeddings
    from handit_service import tracker
    from typing import List, Dict, Any
    import logging

    # Embedding model tracking with batch processing
    class EmbeddingService:
        def __init__(self, model_name: str = "text-embedding-ada-002"):
            self.model = OpenAIEmbeddings(model=model_name)
            self.model = tracker.track_model(
                self.model,
                f"embeddings-{model_name}-production"
            )

        async def get_embeddings(
            self,
            texts: List[str],
            batch_size: int = 100
        ) -> List[List[float]]:
            try:
                # Process in batches
                all_embeddings = []
                for i in range(0, len(texts), batch_size):
                    batch = texts[i:i + batch_size]
                    embeddings = await self.model.aembed_documents(batch)
                    all_embeddings.extend(embeddings)
                return all_embeddings
            except Exception as e:
                logging.error(f"Embedding error: {str(e)}")
                raise

        async def get_similarity(
            self,
            text1: str,
            text2: str
        ) -> float:
            try:
                # Get embeddings for both texts
                embeddings = await self.model.aembed_documents([text1, text2])
                
                # Calculate cosine similarity
                similarity = this._cosine_similarity(embeddings[0], embeddings[1])
                return similarity
            except Exception as e:
                logging.error(f"Similarity error: {str(e)}")
                raise

    # Usage
    async def main():
        service = EmbeddingService()
        texts = ["Hello world", "Greetings universe"]
        embeddings = await service.get_embeddings(texts)
        similarity = await service.get_similarity(texts[0], texts[1])
    ```
  </Tabs.Tab>
  <Tabs.Tab>
    ```javascript filename="embedding_tracking.js"
    const { trackModel } = require('handit-service');
    const { OpenAIEmbeddings } = require('langchain/embeddings/openai');
    const logger = require('./logger');

    // Embedding model tracking with batch processing
    class EmbeddingService {
        constructor(modelName = 'text-embedding-ada-002') {
            this.model = new OpenAIEmbeddings({ modelName });
            this.model = trackModel(
                this.model,
                `embeddings-${modelName}-production`
            );
        }

        async getEmbeddings(texts, batchSize = 100) {
            try {
                // Process in batches
                const allEmbeddings = [];
                for (let i = 0; i < texts.length; i += batchSize) {
                    const batch = texts.slice(i, i + batchSize);
                    const embeddings = await this.model.embedDocuments(batch);
                    allEmbeddings.push(...embeddings);
                }
                return allEmbeddings;
            } catch (error) {
                logger.error(`Embedding error: ${error.message}`);
                throw error;
            }
        }

        async getSimilarity(text1, text2) {
            try {
                // Get embeddings for both texts
                const embeddings = await this.model.embedDocuments([text1, text2]);
                
                // Calculate cosine similarity
                const similarity = this._cosineSimilarity(embeddings[0], embeddings[1]);
                return similarity;
            } catch (error) {
                logger.error(`Similarity error: ${error.message}`);
                throw error;
            }
        }
    }

    // Usage
    const main = async () => {
        const service = new EmbeddingService();
        const texts = ['Hello world', 'Greetings universe'];
        const embeddings = await service.getEmbeddings(texts);
        const similarity = await service.getSimilarity(texts[0], texts[1]);
    };
    ```
  </Tabs.Tab>
</Tabs>

### 3. Custom Model Tracking

<Tabs items={['Python', 'JavaScript']}>
  <Tabs.Tab>
    ```python filename="custom_model_tracking.py"
    from handit_service import tracker
    from typing import Any, Dict, List, Optional
    import logging

    # Custom model tracking with performance monitoring
    class CustomModel:
        def __init__(self, model_id: str):
            self.model_id = model_id
            self.model = self._initialize_model()
            self.model = tracker.track_model(
                self.model,
                f"custom-{model_id}-production"
            )

        def _initialize_model(self) -> Any:
            # Initialize your custom model here
            return model

        async def predict(
            self,
            input_data: Dict[str, Any],
            parameters: Optional[Dict[str, Any]] = None
        ) -> Dict[str, Any]:
            try:
                # Add custom parameters
                if parameters:
                    input_data.update(parameters)

                # Make prediction
                result = await self.model(input_data)
                return result
            except Exception as e:
                logging.error(f"Prediction error: {str(e)}")
                raise

    # Usage
    async def main():
        model = CustomModel("my-custom-model")
        result = await model.predict(
            {"text": "Sample input"},
            parameters={"temperature": 0.7}
        )
    ```
  </Tabs.Tab>
  <Tabs.Tab>
    ```javascript filename="custom_model_tracking.js"
    const { trackModel } = require('handit-service');
    const logger = require('./logger');

    // Custom model tracking with performance monitoring
    class CustomModel {
        constructor(modelId) {
            this.modelId = modelId;
            this.model = this._initializeModel();
            this.model = trackModel(
                this.model,
                `custom-${modelId}-production`
            );
        }

        _initializeModel() {
            // Initialize your custom model here
            return model;
        }

        async predict(inputData, parameters = null) {
            try {
                // Add custom parameters
                if (parameters) {
                    inputData = { ...inputData, ...parameters };
                }

                // Make prediction
                const result = await this.model(inputData);
                return result;
            } catch (error) {
                logger.error(`Prediction error: ${error.message}`);
                throw error;
            }
        }
    }

    // Usage
    const main = async () => {
        const model = new CustomModel('my-custom-model');
        const result = await model.predict(
            { text: 'Sample input' },
            { temperature: 0.7 }
        );
    };
    ```
  </Tabs.Tab>
</Tabs>

## Best Practices

1. **Model Configuration**
   - Use meaningful model IDs
   - Include environment information
   - Track model parameters

2. **Error Handling**
   - Implement proper error boundaries
   - Log detailed error information
   - Handle model-specific errors

3. **Performance Monitoring**
   - Track response times
   - Monitor token usage
   - Identify bottlenecks

4. **Data Management**
   - Sanitize sensitive data
   - Handle large inputs
   - Manage conversation history

<Callout type="warning">
  Always implement proper error handling and logging when tracking models to ensure you can debug issues effectively.
</Callout>

## Advanced Usage

### 1. Model Performance Tracking

<Tabs items={['Python', 'JavaScript']}>
  <Tabs.Tab>
    ```python filename="performance_tracking.py"
    from handit_service import tracker
    from typing import Dict, Any
    import time
    import logging

    # Model performance tracking
    class PerformanceTracker:
        def __init__(self, model, model_id: str):
            self.model = tracker.track_model(model, model_id)
            self.metrics: Dict[str, Any] = {}

        async def track_performance(
            self,
            input_data: Dict[str, Any]
        ) -> Dict[str, Any]:
            try:
                start_time = time.time()
                result = await self.model(input_data)
                end_time = time.time()

                # Track metrics
                self.metrics.update({
                    "execution_time": end_time - start_time,
                    "input_size": len(str(input_data)),
                    "output_size": len(str(result))
                })

                return result
            except Exception as e:
                logging.error(f"Performance tracking error: {str(e)}")
                raise
    ```
  </Tabs.Tab>
  <Tabs.Tab>
    ```javascript filename="performance_tracking.js"
    const { trackModel } = require('handit-service');
    const logger = require('./logger');

    // Model performance tracking
    class PerformanceTracker {
        constructor(model, modelId) {
            this.model = trackModel(model, modelId);
            this.metrics = {};
        }

        async trackPerformance(inputData) {
            try {
                const startTime = Date.now();
                const result = await this.model(inputData);
                const endTime = Date.now();

                // Track metrics
                this.metrics = {
                    executionTime: endTime - startTime,
                    inputSize: JSON.stringify(inputData).length,
                    outputSize: JSON.stringify(result).length
                };

                return result;
            } catch (error) {
                logger.error(`Performance tracking error: ${error.message}`);
                throw error;
            }
        }
    }
    ```
  </Tabs.Tab>
</Tabs>

### 2. Model Chain Tracking

<Tabs items={['Python', 'JavaScript']}>
  <Tabs.Tab>
    ```python filename="chain_tracking.py"
    from handit_service import tracker
    from typing import List, Dict, Any
    import logging

    # Model chain tracking
    class ModelChain:
        def __init__(self, models: List[Any], chain_id: str):
            self.models = [
                tracker.track_model(model, f"{chain_id}-{i}")
                for i, model in enumerate(models)
            ]

        async def process(
            self,
            input_data: Dict[str, Any]
        ) -> Dict[str, Any]:
            try:
                result = input_data
                for model in self.models:
                    result = await model(result)
                return result
            except Exception as e:
                logging.error(f"Chain processing error: {str(e)}")
                raise
    ```
  </Tabs.Tab>
  <Tabs.Tab>
    ```javascript filename="chain_tracking.js"
    const { trackModel } = require('handit-service');
    const logger = require('./logger');

    // Model chain tracking
    class ModelChain {
        constructor(models, chainId) {
            this.models = models.map((model, i) => 
                trackModel(model, `${chainId}-${i}`)
            );
        }

        async process(inputData) {
            try {
                let result = inputData;
                for (const model of this.models) {
                    result = await model(result);
                }
                return result;
            } catch (error) {
                logger.error(`Chain processing error: ${error.message}`);
                throw error;
            }
        }
    }
    ```
  </Tabs.Tab>
</Tabs>

<Callout type="info">
  Model Tracing provides comprehensive tracking capabilities for all your AI models, helping you monitor performance and debug issues effectively.
</Callout>

<Callout type="success">
  By implementing Model Tracing in your application, you can gain valuable insights into your AI models' behavior and optimize their performance.
</Callout>
