---
title: 'CLI Tracing Setup'
sidebarTitle: 'CLI Setup'
---

import { Callout } from "nextra/components"
import { Steps } from "nextra/components"
import { Tabs } from "nextra/components"

# CLI Tracing Setup

> **Set up comprehensive AI agent tracing in minutes using the Handit CLI.** This guide covers the complete CLI workflow for generating tracing code and configuring observability for your AI agents.

<Callout type="info">
  **Prerequisites**: You need Node.js installed and a Handit.ai account. The CLI will handle all SDK installation and configuration automatically.
</Callout>

## Quick Setup

### Step 1: Install the Handit CLI

```bash filename="terminal"
npm install -g @handit.ai/cli
```

### Step 2: Run Setup Command

```bash filename="terminal"
handit-cli setup
```

The CLI will guide you through an interactive setup process:

<Steps>
### Account Connection
- Log into your Handit.ai account (opens browser if needed)
- Verify your integration token
- Select your project/workspace

### Project Analysis
- Scan your codebase to identify AI agent patterns
- Detect existing LLM calls and agent functions
- Suggest optimal tracing integration points

### Code Generation
- Generate tracing configuration files
- Create SDK initialization code
- Add tracing wrappers to your agent functions
- Set up environment variable templates

### Validation
- Test the generated configuration
- Verify connection to Handit.ai platform
- Confirm tracing is working correctly
</Steps>

## Generated Code Structure

After running the setup, the CLI creates several files in your project:

### Configuration Files

<Tabs items={["Python", "JavaScript"]} defaultIndex="0">
<Tabs.Tab>
```python filename="handit_config.py"
"""
Auto-generated Handit.ai configuration
Generated by handit-cli setup on 2024-01-15
"""
import os
from handit import HanditTracker

# Initialize tracker with your project settings
tracker = HanditTracker()
tracker.config(
    api_key=os.getenv("HANDIT_API_KEY"),
    project_name="my-ai-agent",
    environment=os.getenv("ENVIRONMENT", "development")
)

# Export for use across your application
__all__ = ['tracker']
```

```env filename=".env.example"
# Handit.ai Configuration
HANDIT_API_KEY=your_integration_token_here
ENVIRONMENT=development

# Add your existing environment variables below
```
</Tabs.Tab>
<Tabs.Tab>
```javascript filename="handit.config.js"
/**
 * Auto-generated Handit.ai configuration
 * Generated by handit-cli setup on 2024-01-15
 */
import { config } from '@handit.ai/node';

// Initialize Handit.ai with your project settings
config({
    apiKey: process.env.HANDIT_API_KEY,
    projectName: 'my-ai-agent',
    environment: process.env.NODE_ENV || 'development'
});

export default config;
```

```env filename=".env.example"
# Handit.ai Configuration
HANDIT_API_KEY=your_integration_token_here
NODE_ENV=development

# Add your existing environment variables below
```
</Tabs.Tab>
</Tabs>

### Agent Wrapper Code

The CLI automatically generates tracing wrappers for your detected agent functions:

<Tabs items={["Python", "JavaScript"]} defaultIndex="0">
<Tabs.Tab>
```python filename="agents/customer_service_traced.py"
"""
Auto-generated tracing wrapper for CustomerServiceAgent
Generated by handit-cli setup
"""
from handit_config import tracker
from .customer_service import CustomerServiceAgent as OriginalAgent

class CustomerServiceAgent(OriginalAgent):
    """Traced version of CustomerServiceAgent with automatic observability"""
    
    @tracker.start_agent_tracing()
    async def process_customer_request(self, user_message: str, context: dict = None):
        """
        Process customer request with automatic tracing
        Original function wrapped with Handit.ai observability
        """
        return await super().process_customer_request(user_message, context)
    
    @tracker.trace_agent_node("response_generation")
    async def generate_response(self, message: str, history: list = None):
        """
        Generate response with node-level tracing
        Automatically tracks inputs, outputs, and performance
        """
        return await super().generate_response(message, history)
```
</Tabs.Tab>
<Tabs.Tab>
```javascript filename="agents/customerServiceTraced.js"
/**
 * Auto-generated tracing wrapper for CustomerServiceAgent
 * Generated by handit-cli setup
 */
import { startAgentTracing, traceAgentNode } from '@handit.ai/node';
import { CustomerServiceAgent as OriginalAgent } from './customerService.js';
import './handit.config.js';

export class CustomerServiceAgent extends OriginalAgent {
    /**
     * Process customer request with automatic tracing
     * Original function wrapped with Handit.ai observability
     */
    processCustomerRequest = startAgentTracing(async (userMessage, context = {}) => {
        return await super.processCustomerRequest(userMessage, context);
    });

    /**
     * Generate response with node-level tracing
     * Automatically tracks inputs, outputs, and performance
     */
    generateResponse = traceAgentNode({
        agentNodeId: 'response_generation',
        callback: async (message, history = []) => {
            return await super.generateResponse(message, history);
        }
    });
}
```
</Tabs.Tab>
</Tabs>

## Customizing Generated Code

### Modifying Tracing Configuration

You can customize the generated tracing configuration:

```python filename="handit_config.py"
# Add custom configuration after CLI generation
tracker.config(
    api_key=os.getenv("HANDIT_API_KEY"),
    project_name="my-ai-agent",
    environment=os.getenv("ENVIRONMENT", "development"),
    # Custom settings
    batch_size=50,          # Batch traces for better performance
    flush_interval=30,      # Send traces every 30 seconds
    debug_mode=True,        # Enable debug logging
    sampling_rate=1.0       # Trace 100% of requests (reduce for high volume)
)
```

### Adding Custom Tracing Points

Extend the generated code with additional tracing:

<Tabs items={["Python", "JavaScript"]} defaultIndex="0">
<Tabs.Tab>
```python filename="agents/customer_service_traced.py"
# Add custom tracing to the generated wrapper
@tracker.trace_agent_node("intent_analysis")
async def analyze_intent(self, user_message: str):
    """Custom tracing for intent analysis"""
    return await super().analyze_intent(user_message)

@tracker.trace_agent_node("knowledge_retrieval")
async def retrieve_knowledge(self, query: str):
    """Custom tracing for knowledge base queries"""
    return await super().retrieve_knowledge(query)
```
</Tabs.Tab>
<Tabs.Tab>
```javascript filename="agents/customerServiceTraced.js"
// Add custom tracing to the generated wrapper
analyzeIntent = traceAgentNode({
    agentNodeId: 'intent_analysis',
    callback: async (userMessage) => {
        return await super.analyzeIntent(userMessage);
    }
});

retrieveKnowledge = traceAgentNode({
    agentNodeId: 'knowledge_retrieval', 
    callback: async (query) => {
        return await super.retrieveKnowledge(query);
    }
});
```
</Tabs.Tab>
</Tabs>

## CLI Management Commands

### Managing Your Setup

If you need to update your tracing configuration or fix issues:

```bash
# Re-run setup to update configuration
handit-cli setup
```

The CLI will:
- Detect any changes in your codebase
- Update tracing configuration as needed
- Regenerate integration code if necessary
- Test the connection to Handit.ai

**When to re-run setup:**
- After adding new agent functions
- When changing your project structure
- If tracing stops working
- To update to latest SDK version

## Integration Patterns

### Existing Codebase Integration

The CLI adapts to different codebase structures:

**Class-based Agents:**
```python
# Original code
class CustomerAgent:
    def process_request(self, msg): pass

# CLI generates traced wrapper
class TracedCustomerAgent(CustomerAgent):
    @tracker.start_agent_tracing()
    def process_request(self, msg): 
        return super().process_request(msg)
```

**Function-based Agents:**
```python
# Original code  
async def handle_customer_query(query):
    return process_query(query)

# CLI generates traced version
@tracker.start_agent_tracing()
async def traced_handle_customer_query(query):
    return await handle_customer_query(query)
```

**Framework Integration:**
```python
# FastAPI integration
from fastapi import FastAPI
from handit_config import tracker

app = FastAPI()

@app.post("/chat")
@tracker.start_agent_tracing()
async def chat_endpoint(message: str):
    return await process_chat(message)
```

### Multiple Agent Support

For projects with multiple agents:

```python filename="agents/__init__.py"
"""
Auto-generated multi-agent tracing setup
"""
from .customer_service_traced import CustomerServiceAgent
from .technical_support_traced import TechnicalSupportAgent
from .sales_agent_traced import SalesAgent

# Export traced versions
__all__ = [
    'CustomerServiceAgent',
    'TechnicalSupportAgent', 
    'SalesAgent'
]
```

## Best Practices

### Development Workflow

1. **Run CLI setup** when starting a new project
2. **Use traced versions** of your agents in development
3. **Validate tracing** before deploying to production
4. **Update configuration** when adding new agent functions

### Production Considerations

<div className="grid grid-cols-2 gap-4 mt-4">
  <div>
    <h4>âœ… Recommended Practices</h4>
    - Use environment variables for API keys
    - Set appropriate sampling rates for high traffic
    - Monitor tracing overhead in production
    - Keep traced and original versions in sync
  </div>
  <div>
    <h4>ðŸ”§ Performance Optimization</h4>
    - Batch traces for better performance
    - Use async tracing for high-throughput systems
    - Configure flush intervals appropriately
    - Monitor memory usage with large traces
  </div>
</div>

### Code Organization

```
my-ai-project/
â”œâ”€â”€ agents/
â”‚   â”œâ”€â”€ original/              # Original agent implementations
â”‚   â”‚   â”œâ”€â”€ customer_service.py
â”‚   â”‚   â””â”€â”€ technical_support.py
â”‚   â”œâ”€â”€ traced/                # CLI-generated traced versions
â”‚   â”‚   â”œâ”€â”€ customer_service_traced.py
â”‚   â”‚   â””â”€â”€ technical_support_traced.py
â”‚   â””â”€â”€ __init__.py           # Export traced versions
â”œâ”€â”€ handit_config.py          # CLI-generated configuration
â”œâ”€â”€ .env.example              # Environment template
â””â”€â”€ requirements.txt          # Updated with handit-sdk
```

## Troubleshooting

### CLI Setup Issues

**Command not found:**
```bash
# Reinstall CLI
npm uninstall -g @handit.ai/cli
npm install -g @handit.ai/cli
```

**Setup fails during account connection:**
- Ensure you have a valid Handit.ai account
- Check internet connection for browser authentication
- Verify your account has API access enabled

**Code generation errors:**
- Ensure your project structure follows standard patterns
- Check that your agent functions are properly defined
- Try running with `--verbose` flag for detailed error info

### Runtime Issues

**Traces not appearing in dashboard:**
- Verify API key is correctly set in environment
- Check network connectivity to Handit.ai
- Ensure you're using the traced versions of your agents

**Performance issues:**
- Reduce sampling rate: `sampling_rate=0.1` (10% of traces)
- Increase batch size: `batch_size=100`
- Adjust flush interval: `flush_interval=60`

## Next Steps

- View your traces in the [Handit.ai Dashboard](https://beta.handit.ai)
- Set up [Evaluation](/evaluation/quickstart) to assess trace quality
- Configure [Optimization](/optimization/quickstart) for continuous improvement
- Explore [Advanced Tracing Features](/tracing/tracing_features/overview)

<Callout type="success">
  **Ready to observe your AI!** Your agents now have comprehensive tracing. Monitor performance, debug issues, and optimize behavior using the generated observability infrastructure.
</Callout>