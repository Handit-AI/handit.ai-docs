---
title: 'Tracing Overview'
sidebarTitle: 'Tracing'
---

import { Callout } from "nextra/components"
import { Steps } from "nextra/components"
import { Tabs } from "nextra/components"
import { Cards } from 'nextra/components'

# Tracing

Tracing is an observability technique that allows you to follow the execution flow of your AI application. It's like mounting an action camera on each method to chronicle exactly what happened.

<details>
<summary>**What Handit Tracing records?**</summary>

- **What ran** - Every operation, LLM call, or function
  - LLM invocations and their parameters
  - Tool executions and their results
  - Function calls and their context
  - Chain of operations in complex workflows

- **With what data** - The inputs and outputs of each step
  - Prompts and completions for LLMs
  - Input parameters and return values
  - Context and metadata
  - Error messages and stack traces

- **How long it took** - The duration of each operation
  - Total execution time
  - Token generation latency
  - Network request duration
  - Processing overhead

- **Whether it succeeded or failed** - The final state of each execution
  - Success/failure status
  - Error types and messages
  - Retry attempts and results
  - Recovery actions taken

</details>  

<Callout type="info">
  Tracing is essential for understanding how your AI application behaves, identifying bottlenecks, and debugging issues.
</Callout>


<details>
<summary>**Why You Need Tracing?**</summary>

- **Visibility** - See exactly what's happening in your AI application
   - Track every LLM call, tool execution, and function
   - Monitor prompt engineering in real-time
   - Understand the full context of each operation
   - Get insights into your application's behavior

- **Debugging** - Quickly identify where and why something fails
   - Pinpoint exact failure points in complex chains
   - Access detailed error logs and stack traces
   - See the exact inputs that caused issues
   - Reduce time-to-resolution for problems

- **Optimization** - Find and improve parts of your system
   - Identify slow operations and bottlenecks
   - Track token usage and costs
   - Measure response times and latency
   - Optimize prompts and model parameters

- **Monitoring** - Keep an eye on real-time performance
   - Track system health and reliability
   - Monitor resource usage and costs
   - Get alerts for anomalies
   - Make data-driven decisions

</details>  

<Callout type="warning">
  Without tracing, you're flying blind. Every production AI system needs observability to ensure reliability and performance.
</Callout>


## Main Components

| Component | Description | Example |
|-----------|-------------|---------|
| **Agent Tracing** | The main orchestrator, the root | The main API endpoint processing requests. (The endpoint or the main function that executes the entire workflow) |
| **LLM Node Tracing** | This essential component keeps a detailed record of every interaction with your LLM | GPT-4, Claude, your custom LLM model |
| **Tool Tracing** | This powerful tracker ensures you never miss a beat when monitoring your helper functions and custom tools | Custom utility, API Tool, RAG Tool, data processing functions |

## Tracing Functions

### Agent Tracing
This powerful tool gives you complete visibility into your entire workflow, from start to finish. It acts as the root of your tracing tree, important to automatically collecting and correlating all operations within your Application.

<details>
<summary>**Details**</summary>

- Tracks the entire agent execution flow
  - Captures the complete sequence of operations
  - Maintains parent-child relationships between operations
  - Provides a hierarchical view of your workflow
- Automatically captures start and end times
  - Records precise timestamps for each phase
  - Calculates total execution duration
  - Tracks time spent in each sub-operation
- Records success/failure status
  - Captures detailed error information
  - Tracks retry attempts and recovery actions
  - Provides status summaries for the entire workflow
- Links all child operations together
  - Creates a complete trace of the execution path
  - Enables end-to-end request tracking
  - Helps identify bottlenecks and dependencies

</details>

### LLM Node Tracing
This essential component keeps a detailed record of every interaction with your LLM models (GPT-4, Claude, etc.), helping you understand their behavior and optimize their performance.

<details>
<summary>**Details**</summary>

- Wraps AI models (LLMs, embeddings)
  - Supports all major model providers
  - Handles both synchronous and asynchronous calls
  - Maintains model-specific configurations
- Records prompts and responses
  - Captures complete prompt history
  - Stores model responses and completions
  - Tracks prompt engineering changes
- Tracks token usage and latency
  - Monitors input and output tokens
  - Calculates token costs
  - Measures response times
- Captures model parameters
  - Records temperature and other settings
  - Tracks model version information
  - Stores custom model configurations

</details>

### Tool Tracing
The silent guardian of your utility functions. This powerful tracker ensures you never miss a beat when monitoring your helper functions and custom tools. It's essential for understanding how your tools interact with the rest of your AI application.

<details>
<summary>**Details**</summary>

- Monitors tool execution
  - Tracks tool lifecycle events
  - Records tool-specific metrics
  - Monitors tool health and status
- Records input/output data
  - Captures tool parameters
  - Stores tool results
  - Tracks data transformations
- Tracks execution time
  - Measures tool performance
  - Identifies slow operations
  - Monitors resource usage
- Handles errors and retries
  - Captures tool-specific errors
  - Manages retry attempts
  - Provides error context

</details>

<Callout type="info">
  Each tracing function is designed to work seamlessly together, giving you a complete picture of your AI application's behavior. Choose the right tool for each part of your workflow, and combine them to create a comprehensive tracing solution.
</Callout>

<Callout type="success">
  With Handit.ai, you can implement tracing in minutes and start getting valuable insights about your AI application.
</Callout>


**Integrate into your stack in minutes:**
<Cards.Card title="Quickstart" href="/tracing/quickstart" arrow />