---
title: 'Optimization Token Setup'
sidebarTitle: 'Token Setup'
---

import { Callout } from "nextra/components"
import { Steps } from "nextra/components"
import { Tabs } from "nextra/components"

# Optimization Token Setup

Enable self-improving AI and CI/CD deployment by selecting an optimization token. This single configuration activates all optimization features automatically.

<Callout type="info">
  Once you select an optimization token, self-improving AI and CI/CD deployment activate immediately. The AI will start analyzing your evaluation data and generating optimized prompts automatically.
</Callout>

## How It Works

Setting up optimization is simple:

<Steps>
### Go to Settings
Navigate to Settings → Model Tokens in your dashboard

### Select Optimization Token
Choose which AI model token to use for optimization analysis

### Automatic Activation
Self-improving AI and CI/CD deployment activate immediately

### Start Optimizing
The system begins analyzing evaluation data and generating improvements
</Steps>

*[Image placeholder: Simple token selection workflow]*

## Token Selection Process

### Simple Setup

**Navigate to Model Tokens:**

1. **Go to Settings**
   - Click **Settings** in your dashboard
   - Select **Model Tokens**
   - Find the **Optimization** section

2. **Select Your Token**
   - Choose from your existing model tokens
   - Click **Use for Optimization**
   - Confirm your selection

*[Image placeholder: Settings navigation to model tokens]*

**What You'll See:**
- Your existing evaluation tokens (can be reused for optimization)
- Any additional model tokens you've configured
- Clear recommendations for best optimization performance
- Simple one-click selection process

*[Image placeholder: Token selection interface with available options]*

## Recommended Tokens

### Best Performance Options

<Tabs items={["GPT-4o (Best)", "GPT-4-turbo (Good)", "GPT-3.5-turbo (Basic)"]} defaultIndex="0">
<Tabs.Tab>

**GPT-4o - Highest Quality Optimization**

**Why Choose GPT-4o:**
- Superior analysis of evaluation data
- Highest quality prompt improvements
- Best understanding of complex quality issues
- Most reliable optimization results

**Perfect For:**
- Customer-facing applications
- Critical business processes
- When quality is the top priority
- Production systems requiring best results

**What Happens When Selected:**
- Self-improving AI uses advanced reasoning
- Generates sophisticated prompt improvements
- Provides detailed analysis of quality issues
- Creates highly effective optimizations

</Tabs.Tab>
<Tabs.Tab>

**GPT-4-turbo - Balanced Performance**

**Why Choose GPT-4-turbo:**
- Good analysis capabilities
- Faster optimization generation
- Cost-effective for regular use
- Reliable performance for most cases

**Perfect For:**
- Regular business applications
- Frequent optimization cycles
- Balancing quality and speed
- Most standard use cases

**What Happens When Selected:**
- Self-improving AI provides solid analysis
- Generates effective prompt improvements
- Faster optimization cycles
- Good balance of quality and efficiency

</Tabs.Tab>
<Tabs.Tab>

**GPT-3.5-turbo - Cost-Effective**

**Why Choose GPT-3.5-turbo:**
- Most cost-effective option
- Fast optimization generation
- Good for basic improvements
- High-volume optimization

**Perfect For:**
- Non-critical applications
- Testing and experimentation
- High-frequency optimization
- Budget-conscious deployments

**What Happens When Selected:**
- Self-improving AI provides basic analysis
- Generates simple prompt improvements
- Very fast optimization cycles
- Cost-effective continuous improvement

</Tabs.Tab>
</Tabs>

## What Activates Automatically

When you select an optimization token, these features activate instantly:

**Self-Improving AI:**
- Analyzes your evaluation data for quality issues
- Generates improved prompt versions automatically
- Creates A/B testing configurations

**Background A/B Testing:**
- Tests new optimizations using cost-efficient sampling
- Provides statistical validation and performance comparisons

**Release Hub:**
- Shows optimization results and enables prompt comparison
- Provides deployment recommendations and tracks version history

**CI/CD Integration:**
- Makes optimized prompts available via SDK
- Enables instant deployment with rollback capabilities

*[Image placeholder: Features activating automatically after token selection]*

## Using Your Optimizations

Once optimization is active, you can access results through three main areas:

**A/B Testing Results:**
- Performance comparisons with statistical confidence
- Improvement metrics and testing progress

**Release Hub:**
- Compare current vs optimized prompts
- Deploy optimizations and track history

**SDK Integration:**
- Fetch optimized prompts in your applications
- Automatic updates with seamless integration

*[Image placeholder: Using optimization results across the platform]*

## Next Steps

Ready to start optimizing your prompts?

- Go to **Settings → Model Tokens** to select your optimization token
- [Monitor A/B testing results](/optimization/optimization_features/ab_testing) as they become available
- [Use Release Hub](/optimization/guide/release_hub) to deploy optimizations
- [Integrate with SDK](/optimization/optimization_features/cicd_deployment) to fetch optimized prompts

<Callout type="success">
  **One-click activation!** Select your optimization token and all optimization features activate immediately. Self-improving AI will start analyzing your data and generating improvements automatically.
</Callout> 